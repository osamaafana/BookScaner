# BookScanner Environment Configuration
# Copy this file to .env and fill in your actual values

# =============================================================================
# APP CONFIGURATION
# =============================================================================
APP_ENV=dev
API_BASE_URL=http://localhost:8000
LOG_LEVEL=INFO
METRICS_ENABLED=true
MAX_UPLOAD_MB=10

# =============================================================================
# CORS CONFIGURATION
# =============================================================================
# Comma-separated list of allowed origins
CORS_ORIGINS=http://localhost:5173,http://localhost:3000

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================
# PostgreSQL Database URL (Neon DB recommended)
# Format: postgresql://username:password@host:port/database?sslmode=require
POSTGRES_URL=postgresql://your_username:your_password@your_host:5432/your_database?sslmode=require

# =============================================================================
# CACHE CONFIGURATION
# =============================================================================
# Redis Cache URL (Upstash recommended)
# Format: redis://default:token@host:port
REDIS_URL=redis://default:your_token@your_host:6379

# =============================================================================
# AI PROVIDERS CONFIGURATION
# =============================================================================

# Groq API (Primary AI provider)
GROQ_API_KEY=your_groq_api_key_here
GROQ_MONTHLY_CAP_USD=10
GROQ_VISION_MODEL=meta-llama/llama-4-scout-17b-16e-instruct

# Ollama (Local AI - optional)
OLLAMA_RECS_MODEL=llama-3.1-8b-instant

# Google Cloud Vision (Fallback OCR)
GOOGLE_VISION_API_KEY=your_google_vision_api_key
GOOGLEBOOKS_API_KEY=your_google_books_api_key

# NVIDIA API (Advanced AI - optional)
NVIDIA_API_KEY=your_nvidia_api_key
NVIDIA_BASE_URL=https://integrate.api.nvidia.com
NVIDIA_MODEL_NAME=meta/llama-3.1-70b-instruct

# =============================================================================
# SECURITY CONFIGURATION
# =============================================================================
# JWT Secret (64 characters recommended)
JWT_SECRET=your_64_character_jwt_secret_here_change_this_in_production

# Admin Token (for admin panel access)
ADMIN_TOKEN=your_admin_token_here_change_this_in_production

# =============================================================================
# RATE LIMITING CONFIGURATION
# =============================================================================
RATE_LIMIT_PER_DEVICE_HOURLY=100
RATE_LIMIT_PER_DEVICE_DAILY=500
RATE_LIMIT_PER_IP_PER_MIN=50
RATE_LIMIT_PER_IP_DAILY=1000

# =============================================================================
# GATEWAY SERVER CONFIGURATION
# =============================================================================
PORT=3001
BACKEND_URL=http://localhost:8000

# Rate Limiting
RL_WINDOW_MS=300000
RL_MAX=120
BURST_PER_SEC=20

# Security
SECURE_COOKIES=false

# =============================================================================
# METADATA CACHE CONFIGURATION
# =============================================================================
# Cache TTL in seconds (432000 = 5 days)
METADATA_TTL_SECS=432000

# =============================================================================
# SETUP INSTRUCTIONS
# =============================================================================
# 1. Copy this file to .env
# 2. Get API keys from:
#    - Groq: https://console.groq.com/
#    - Google Cloud: https://console.cloud.google.com/
#    - NVIDIA: https://console.nvidia.com/
# 3. Set up databases:
#    - PostgreSQL: https://neon.tech/ (recommended)
#    - Redis: https://upstash.com/ (recommended)
# 4. Update all placeholder values with your actual credentials
# 5. Run: docker compose -f deployment/docker-compose-full.yml up --build
